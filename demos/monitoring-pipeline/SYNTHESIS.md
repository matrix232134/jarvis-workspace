# Research Pipeline Synthesis: Monitoring Stack for JARVIS
> Pipeline: 3 research agents (sequential — sub-agents blocked by pairing) + live Tavily search
> Queries executed: 9 searches + 2 page extractions
> Topic: Self-hosted monitoring for solo Windows operator
> Date: 2026-02-22

---

## Executive Summary

Install **Uptime-Kuma** (service availability) and **Netdata** (host performance). Together they cost ~110-160MB RAM, cover both "is it up?" and "how is it performing?", and integrate directly with JARVIS's existing heartbeat architecture. No MCP servers needed yet — direct API polling is simpler at this scale.

---

## The Stack

| Layer | Tool | What It Monitors | RAM | Port | Install |
|-------|------|-----------------|-----|------|---------|
| Availability | **Uptime-Kuma** | Service up/down, response time, certs | ~60MB | 3001 | `git clone` + `npm run setup` |
| Performance | **Netdata** | CPU, memory, disk, network, processes | ~50-100MB | 19999 | MSI installer |
| Alerting | **Telegram** (native in both) | — | — | — | Configure in each UI |
| Orchestration | **JARVIS heartbeat** | Polls both APIs every 15min | — | — | Already built |

## Key Research Findings

1. **Uptime-Kuma + Netdata is an established pattern** — Netdata's own comparison page recommends this exact combination (source: netdata.cloud/comparisons/uptimekuma)
2. **No MCP servers needed yet** — Uptime-Kuma and Netdata both have REST APIs; direct polling is simpler than adding MCP layers for 2 tools
3. **Grafana MCP server exists** (official, by Grafana team) — add it later when Grafana is deployed
4. **Prometheus MCP server exists** (freepik-company/prometheus-mcp) — add it later if Prometheus is deployed
5. **No Uptime-Kuma or Netdata MCP servers exist** — identified as ecosystem gap; not worth building at current scale

## Phased Rollout

### Phase 1: Now (~15 min setup)
- [ ] Install Uptime-Kuma: `git clone https://github.com/louislam/uptime-kuma.git`
- [ ] `cd uptime-kuma && npm run setup && node server/server.js`
- [ ] Add monitors: OpenClaw gateway (localhost:18789), JARVIS bridge (localhost:19300)
- [ ] Configure Telegram notification
- [ ] Install Netdata Windows agent (MSI from netdata.cloud)
- [ ] Verify both dashboards accessible

### Phase 2: Next Week
- [ ] Create JARVIS standing order for monitoring-health
- [ ] Add API polling to heartbeat cycle
- [ ] Configure Uptime-Kuma webhook → OpenClaw for real-time DOWN alerts
- [ ] Add monitoring summary to morning briefing

### Phase 3: When Scale Demands (5+ services)
- [ ] Deploy Grafana for unified dashboards
- [ ] Add `mcp-grafana` MCP server for conversational queries
- [ ] Consider Prometheus if metric retention >7 days needed
- [ ] Add `prometheus-mcp` for PromQL from JARVIS

## What This Demo Showed

| Capability | Status |
|------------|--------|
| Live web research (Tavily) | ✅ 9 queries, 2 extractions |
| MCP ecosystem survey | ✅ Found 6 relevant servers, identified 2 gaps |
| Source verification | ✅ All claims traced to specific sources |
| Parallel sub-agents | ❌ Blocked (gateway pairing not configured) |
| Cross-referencing findings | ✅ Netdata comparison page confirmed complementary pattern |
| Actionable output | ✅ Phased plan with specific commands |

## Source Reports
- [01 — Tool Comparison](01-tool-comparison.md) — Uptime-Kuma vs Netdata vs Gatus vs enterprise options
- [02 — MCP Ecosystem](02-mcp-ecosystem.md) — Available MCP servers for monitoring
- [03 — Integration Architecture](03-integration-architecture.md) — How to wire it all into JARVIS

---

## Remaining Blocker

Sub-agents still require gateway pairing configuration. Once fixed, this same pipeline runs 3 agents in parallel — cutting research time by ~60%. Run `openclaw configure` and check spawner/pairing settings.

---
*Generated by JARVIS Research Pipeline v2 | 2026-02-22 | 9 live searches, 4 output files*
